{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd19c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bug: No target data being generated\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def predict_option_price(tickers, horizon, n_trees=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    # Fetch historical data for the tickers and calculate daily returns\n",
    "    stock_data = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Close']]\n",
    "        ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
    "        stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "    returns_df = stock_data.pct_change().dropna()\n",
    "\n",
    "    # If there are not enough datapoints or tickers, return None\n",
    "    if len(tickers) == 0:\n",
    "        print(\"Empty list of tickers\")\n",
    "        return None\n",
    "    if len(returns_df) < horizon:\n",
    "        print(f\"Not enough data points. Try using smaller horizon or adjust the time frame for the historical data.\")\n",
    "        return None\n",
    "    \n",
    "    # Define the predictors and the target variables\n",
    "    predictors = returns_df.iloc[-horizon:,:-len(tickers)]\n",
    "    target = returns_df.iloc[-horizon:, len(tickers):]\n",
    "\n",
    "    # Fit a Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees)\n",
    "    rf.fit(predictors, target)\n",
    "\n",
    "    # Predict returns over the given horizon\n",
    "    predicted_returns = rf.predict(predictors)\n",
    "\n",
    "    # Calculate option prices based on predicted returns\n",
    "    option_values = []\n",
    "    for i in range(len(tickers)):\n",
    "        predicted_return_series = predicted_returns[:,i]\n",
    "        stock_price = stock_data[f\"{tickers[i]}_Close\"][-1]\n",
    "        call_value = max(stock_price * (1 + predicted_return_series) - stock_price, 0)\n",
    "        put_value = max(stock_price - stock_price * (1 + predicted_return_series), 0)\n",
    "        option_values.append((call_value, put_value))\n",
    "\n",
    "    return option_values\n",
    "\n",
    "#Example usage\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'META', 'AMZN']\n",
    "horizon = 30\n",
    "option_values = predict_option_price(tickers, horizon)\n",
    "print(option_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b53af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\1108847312.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\1108847312.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\1108847312.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\1108847312.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            AAPL_Close  GOOG_Close  NFLX_Close  AMZN_Close\n",
      "Date                                                      \n",
      "2023-01-18   -0.005370   -0.004123    0.000337   -0.006143\n",
      "2023-01-19    0.000444    0.023208   -0.032329   -0.018647\n",
      "2023-01-20    0.019221    0.057182    0.084616    0.038108\n",
      "2023-01-23    0.023500    0.019440    0.043562    0.002776\n",
      "2023-01-24    0.010063   -0.019761    0.017934   -0.012305\n",
      "...                ...         ...         ...         ...\n",
      "2023-04-10   -0.015972   -0.017906   -0.001002    0.001078\n",
      "2023-04-11   -0.007591   -0.007761   -0.002301   -0.022022\n",
      "2023-04-12   -0.004353   -0.008481   -0.021229   -0.020917\n",
      "2023-04-13    0.034104    0.028227    0.045796    0.046714\n",
      "2023-04-14   -0.002114    0.011739   -0.021838    0.001074\n",
      "\n",
      "[61 rows x 4 columns]\n",
      "Columns of returns_df:\n",
      " Index(['AAPL_Close', 'GOOG_Close', 'NFLX_Close', 'AMZN_Close'], dtype='object')\n",
      "Correlation matrix:\n",
      "            AAPL_Close  GOOG_Close  NFLX_Close  AMZN_Close\n",
      "AAPL_Close    1.000000    0.680864    0.554497    0.576165\n",
      "GOOG_Close    0.680864    1.000000    0.402070    0.691522\n",
      "NFLX_Close    0.554497    0.402070    1.000000    0.475181\n",
      "AMZN_Close    0.576165    0.691522    0.475181    1.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNFLX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMZN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     54\u001b[0m horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m---> 55\u001b[0m option_values \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_option_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(option_values)\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mpredict_option_price\u001b[1;34m(tickers, horizon, n_trees)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Fit a Random Forest Regressor\u001b[39;00m\n\u001b[0;32m     35\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39mn_trees)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Predict returns over the given horizon\u001b[39;00m\n\u001b[0;32m     39\u001b[0m predicted_returns \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(predictors)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def predict_option_price(tickers, horizon, n_trees=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=90)\n",
    "\n",
    "    # Fetch historical data for the tickers and calculate daily returns\n",
    "    stock_data = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Close']]\n",
    "        ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
    "        stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "    returns_df = stock_data.pct_change().dropna()\n",
    "    print(returns_df)\n",
    "\n",
    "    # Check which columns exist and the correlation between them\n",
    "    print(\"Columns of returns_df:\\n\", returns_df.columns)\n",
    "    print(\"Correlation matrix:\")\n",
    "    print(returns_df.corr())\n",
    "\n",
    "    # Make sure that ticker data exists\n",
    "    if len(returns_df.columns) == 0:\n",
    "        print(f\"No data available for tickers: {tickers}\")\n",
    "        return None\n",
    "\n",
    "    # Define the predictors and the target variables\n",
    "    predictors = returns_df.iloc[-horizon:,:-len(tickers)]\n",
    "    target = returns_df.iloc[-horizon:, len(returns_df.columns)-len(tickers):]\n",
    "\n",
    "    # Fit a Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees)\n",
    "    rf.fit(predictors, target)\n",
    "\n",
    "    # Predict returns over the given horizon\n",
    "    predicted_returns = rf.predict(predictors)\n",
    "\n",
    "    # Calculate option prices based on predicted returns\n",
    "    option_values = []\n",
    "    for i in range(len(tickers)):\n",
    "        predicted_return_series = predicted_returns[:,i]\n",
    "        stock_price = stock_data[f\"{tickers[i]}_Close\"][-1]\n",
    "        call_value = max(stock_price * (1 + predicted_return_series) - stock_price, 0)\n",
    "        put_value = max(stock_price - stock_price * (1 + predicted_return_series), 0)\n",
    "        option_values.append((call_value, put_value))\n",
    "\n",
    "    return option_values\n",
    "\n",
    "#Example usage\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'AMZN']\n",
    "horizon = 10\n",
    "option_values = predict_option_price(tickers, horizon)\n",
    "print(option_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcaac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Write very basic neural network\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the generator network\n",
    "def generator(input, output_size):\n",
    "    hidden1 = tf.layers.dense(input, 16, activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, 32, activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, 16, activation=tf.nn.relu)\n",
    "    output = tf.layers.dense(hidden3, output_size)\n",
    "    return output\n",
    "\n",
    "# Define the discriminator network\n",
    "def discriminator(input):\n",
    "    hidden1 = tf.layers.dense(input, 16, activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, 32, activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, 16, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden3, 1)\n",
    "    output = tf.sigmoid(logits)\n",
    "    return output, logits\n",
    "\n",
    "# Define the placeholders and variables for the model\n",
    "input_date = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "input_ticker = tf.placeholder(tf.string, shape=[None, 1])\n",
    "input_strike = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# Turn the ticker into a one-hot encoding\n",
    "tickers = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/stock-tickers.csv')['ticker'].tolist()\n",
    "ticker_one_hot = tf.one_hot(tf.squeeze(tf.where(tf.equal(tickers, input_ticker))), len(tickers))\n",
    "\n",
    "# Concatenate the input date, ticker_one_hot, and strike price into a single input vector\n",
    "input = tf.concat([input_date, ticker_one_hot, input_strike], axis=1)\n",
    "\n",
    "# Create the generator\n",
    "gen_output = generator(input, 1)\n",
    "\n",
    "# Create the discriminator for real data\n",
    "real_disc_output, real_disc_logits = discriminator(input)\n",
    "\n",
    "# Create the discriminator for fake data\n",
    "fake_input = tf.concat([input[:, :2], gen_output], axis=1)\n",
    "fake_disc_output, fake_disc_logits = discriminator(fake_input)\n",
    "\n",
    "# Define the loss functions for the generator and discriminator\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_disc_logits, labels=tf.ones_like(fake_disc_output)))\n",
    "disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_disc_logits, labels=tf.ones_like(real_disc_output))) + tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_disc_logits, labels=tf.zeros_like(fake_disc_output)))\n",
    "\n",
    "# Define the optimizer for the generator and discriminator\n",
    "gen_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(gen_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"generator\"))\n",
    "disc_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(disc_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"discriminator\"))\n",
    "\n",
    "# Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define the function that will price the option\n",
    "def price_option(date, ticker, strike):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Generate a price for the option using the adversarial neural network\n",
    "        price = sess.run(gen_output, feed_dict={input_date: [[date]], input_ticker: [[ticker]], input_strike: [[strike]]})\n",
    "        \n",
    "        # Get the current stock price and calculate the volatility\n",
    "        stock_data = yf.Ticker(ticker).history(period=\"max\")['Close']\n",
    "        returns = pd.DataFrame(stock_data.pct_change())['Close']\n",
    "        volatility = returns.std() * (252 ** 0.5)\n",
    "        \n",
    "        # Calculate the Black-Scholes option price using the generated price and other inputs\n",
    "        S = stock_data.iloc[-1]\n",
    "        K = strike\n",
    "        T = (pd.to_datetime(str(date), format='%Y%m%d') - pd.datetime.now()).days / 365\n",
    "        r = 0.02\n",
    "        d1 = (tf.math.log(S/K) + (r + volatility**2/2)*T) / (volatility * tf.math.sqrt(T))\n",
    "        d2 = d1 - volatility * tf.math.sqrt(T)\n",
    "        N = tf.distributions.Normal(0,1)\n",
    "        option_price = S*N.cdf(d1) - K*tf.math.exp(-r*T)*N.cdf(d2)\n",
    "        \n",
    "        return option_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd66a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the generator network\n",
    "def generator(input, output_size):\n",
    "    hidden1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(input)\n",
    "    hidden2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)(hidden1)\n",
    "    hidden3 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(hidden2)\n",
    "    output = tf.keras.layers.Dense(output_size)(hidden3)\n",
    "    return output\n",
    "\n",
    "# Define the discriminator network\n",
    "def discriminator(input):\n",
    "    hidden1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(input)\n",
    "    hidden2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)(hidden1)\n",
    "    hidden3 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(hidden2)\n",
    "    logits = tf.keras.layers.Dense(1)(hidden3)\n",
    "    output = tf.sigmoid(logits)\n",
    "    return output, logits\n",
    "\n",
    "# Define the variables for the model\n",
    "tickers = \"F\"\n",
    "#pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/stock-tickers.csv')['ticker'].tolist()\n",
    "ticker_one_hot = tf.keras.layers.Input(len(tickers), dtype=tf.float32)\n",
    "input_date = tf.keras.layers.Input(1, dtype=tf.int32)\n",
    "input_ticker = tf.keras.layers.Input(1, dtype=tf.string)\n",
    "input_strike = tf.keras.layers.Input(1, dtype=tf.float32)\n",
    "\n",
    "# Turn the ticker into a one-hot encoding\n",
    "ticker_one_hot_encoded = tf.one_hot(tf.squeeze(tf.where(tf.equal(tickers, input_ticker))), len(tickers))\n",
    "\n",
    "# Concatenate the input date, ticker_one_hot, and strike price into a single input vector\n",
    "input = tf.keras.layers.concatenate([input_date, ticker_one_hot_encoded, input_strike, ticker_one_hot], axis=1)\n",
    "\n",
    "# Create the generator\n",
    "gen_output = generator(input, 1)\n",
    "\n",
    "# Create the discriminator for real data\n",
    "real_disc_output, real_disc_logits = discriminator(input)\n",
    "\n",
    "# Create the discriminator for fake data\n",
    "fake_input = tf.keras.layers.concatenate([input[:, :2], gen_output, ticker_one_hot], axis=1)\n",
    "fake_disc_output, fake_disc_logits = discriminator(fake_input)\n",
    "\n",
    "# Define the loss functions for the generator and discriminator\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_disc_logits, labels=tf.ones_like(fake_disc_output)))\n",
    "disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_disc_logits, labels=tf.ones_like(real_disc_output))) + tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_disc_logits, labels=tf.zeros_like(fake_disc_output)))\n",
    "\n",
    "# Define the optimizer for the generator and discriminator\n",
    "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Define the functions for training the model\n",
    "@tf.function\n",
    "def train_generator(input_date, ticker_one_hot, input_strike):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Concatenate the input date, ticker_one_hot, and strike price into a single input vector\n",
    "        input = tf.keras.layers.concatenate([input_date, ticker_one_hot, input_strike, ticker_one_hot_encoded], axis=1)\n",
    "\n",
    "        # Create the generator and generate fake data\n",
    "        gen_output = generator(input, 1)\n",
    "\n",
    "        # Create the discriminator for fake data\n",
    "        fake_input = tf.keras.layers.concatenate([input[:, :2], gen_output, ticker_one_hot_encoded], axis=1)\n",
    "        fake_disc_output, fake_disc_logits = discriminator(fake_input)\n",
    "\n",
    "        # Calculate the generator loss\n",
    "        gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_disc_logits, labels=tf.ones_like(fake_disc_output)))\n",
    "\n",
    "    # Calculate the gradients and apply them using the optimizer\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "\n",
    "    return gen_loss\n",
    "\n",
    "@tf.function\n",
    "def train_discriminator(input_date, ticker_one_hot, input_strike, real_data):\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        # Concatenate the real and fake data\n",
    "        input = tf.keras.layers.concatenate([input_date, ticker_one_hot, input_strike, ticker_one_hot_encoded], axis=1)\n",
    "        input = tf.concat([real_data, input], axis=0)\n",
    "\n",
    "        #\n",
    "\n",
    "        # Train the model\n",
    "        generator = tf.keras.Model([input_date, input_ticker, input_strike, ticker_one_hot], gen_output, name='generator')\n",
    "        discriminator = tf.keras.Model([input_date, input_ticker, input_strike, ticker_one_hot], real_disc_output, name='discriminator')\n",
    "\n",
    "        for epoch in range(10000):\n",
    "            date = 20221231\n",
    "            ticker = 'AAPL'\n",
    "            strike = 100\n",
    "            price = price_option(date, ticker, strike)\n",
    "\n",
    "            ticker_one_hot_encoded_numpy = tf.one_hot(tf.squeeze(tf.where(tf.equal(tickers, ticker))), len(tickers)).numpy()\n",
    "            input_date_numpy = tf.constant([[date]], dtype=tf.int32).numpy()\n",
    "            input_ticker_numpy = tf.constant([[ticker]], dtype=tf.string).numpy()\n",
    "            input_strike_numpy = tf.constant([[strike]], dtype=tf.float32).numpy()\n",
    "            price_numpy = tf.constant([[price]], dtype=tf.float32).numpy()\n",
    "\n",
    "            train_generator(input_date_numpy, ticker_one_hot_encoded_numpy, input_strike_numpy)\n",
    "            train_discriminator(input_date_numpy, ticker_one_hot_encoded_numpy, input_strike_numpy, price_numpy)\n",
    "\n",
    "            if epoch % 1000 == 0:\n",
    "                print('Epoch:', epoch, 'Price:', price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec62c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Function to create and train the Random Forest model:\n",
    "def train_random_forest(ticker_list):\n",
    "    # Define the start and end dates of the historical data to fetch\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    # Create an empty DataFrame to store the historical data for each ticker\n",
    "    stock_data = pd.DataFrame()\n",
    "\n",
    "    # Fetch historical data for each ticker and store it in the DataFrame\n",
    "    for ticker in ticker_list:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Open', 'Close', 'Volume']]\n",
    "        ticker_data.rename(columns={'Open': f'{ticker}_Open', 'Close': f'{ticker}_Close', 'Volume': f'{ticker}_Volume'}, inplace=True)\n",
    "        stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "\n",
    "    # Calculate daily returns and append them to the DataFrame\n",
    "    returns_df = stock_data.pct_change().dropna()\n",
    "    stock_data = pd.concat([stock_data, returns_df], axis=1)\n",
    "\n",
    "    # Define the predictors and the target variable\n",
    "    predictors = stock_data.drop([f'{ticker}_Close', f'{ticker}_Volume'], axis=1)\n",
    "    target = stock_data[f'{ticker}_Close']\n",
    "\n",
    "    # Impute missing values with the mean of each column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    predictors_imputed = pd.DataFrame(imputer.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "    # Remove any rows containing NaN values from the predictors and target dataframes\n",
    "    df = pd.concat([predictors_imputed, target], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    predictors_nonan = df.drop(f'{ticker}_Close', axis=1)\n",
    "    target_nonan = df[f'{ticker}_Close']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    if len(predictors_nonan) == 0:\n",
    "        print(\"Not enough data points. Try using smaller dataset or adjust train or test sizes.\")\n",
    "        return None\n",
    "    elif len(predictors_nonan) <= 30:\n",
    "        test_size = 0.1\n",
    "    else:\n",
    "        test_size = 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_nonan, target_nonan, test_size=test_size, random_state=4)\n",
    "\n",
    "    # Create and train the Random Forest model\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model's performance on the testing set\n",
    "    r2_score = rf.score(X_test, y_test)\n",
    "    print(f'R-squared score on testing set: {r2_score:.2f}')\n",
    "\n",
    "    # Return the trained model\n",
    "    return rf\n",
    "\n",
    "\n",
    "# Function to predict price range of stock for a defined time horizon\n",
    "def predict_price_range(model, ticker, horizon):\n",
    "    # Define the start and end dates of the historical data to fetch\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    # Fetch historical data for the stock and calculate daily returns\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Open', 'Close', 'Volume']]\n",
    "    daily_returns = stock_data.pct_change().dropna()\n",
    "\n",
    "    # Define the predictors for the given time horizon\n",
    "    predictors = daily_returns.tail(horizon-1).values.reshape(1, -1)\n",
    "\n",
    "    # Predict the price range for the given time horizon\n",
    "    price_range = model.predict(predictors)[0]\n",
    "\n",
    "    print(f'Predicted price range for {ticker} over the next {horizon} days: {price_range:.2f} to {price_range*1.02:.2f}')\n",
    "\n",
    "# Example usage:\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'META', 'AMZN']  # replace with your own list of tickers\n",
    "model = train_random_forest(tickers)\n",
    "predict_price_range(model, 'AAPL', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def train_random_forest(ticker_list):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=90)\n",
    "\n",
    "    stock_data = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Open', 'Close', 'Volume']]\n",
    "        ticker_data.rename(columns={'Open': f'{ticker}_Open', 'Close': f'{ticker}_Close', 'Volume': f'{ticker}_Volume'}, inplace=True)\n",
    "        stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "    returns_df = stock_data.pct_change().dropna()\n",
    "    stock_data = pd.concat([stock_data, returns_df], axis=1)\n",
    "\n",
    "    predictors = stock_data.drop([f'{ticker}_Close', f'{ticker}_Volume'], axis=1)\n",
    "    target = stock_data[f'{ticker}_Close']\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    predictors_imputed = pd.DataFrame(imputer.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "  \n",
    "    df = pd.concat([predictors_imputed, target], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    predictors_nonan = df.drop(f'{ticker}_Close', axis=1)\n",
    "    target_nonan = df[f'{ticker}_Close']\n",
    "\n",
    "    if len(predictors_nonan) == 0:\n",
    "        print(\"Not enough data points. Try using smaller dataset or adjust train or test sizes.\")\n",
    "        return None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_nonan, target_nonan, test_size=0.3, random_state=4)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    return rf\n",
    "\n",
    "\n",
    "def predict_price_range(model, ticker, horizon):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)[['Open', 'Close', 'Volume']]\n",
    "    daily_returns = stock_data.pct_change().dropna()\n",
    "\n",
    "    predictors = daily_returns.tail(horizon-1).values.reshape(1, -1)\n",
    "\n",
    "    if model is not None:\n",
    "        price_range = model.predict(predictors)[0]\n",
    "        print(f'Predicted price range for {ticker} over the next {horizon} days: {price_range:.2f} to {price_range*1.02:.2f}')\n",
    "    else:\n",
    "        print(\"Could not make predictions. Model is None.\")\n",
    "\n",
    "\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'META', 'AMZN']\n",
    "model = train_random_forest(tickers)\n",
    "predict_price_range(model, 'AAPL', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36c5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\2668817413.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\2668817413.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\2668817413.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_21588\\2668817413.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "You cannot set both the how and thresh arguments at the same time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNFLX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     63\u001b[0m horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 64\u001b[0m option_values \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_option_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(option_values)\n",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m, in \u001b[0;36mpredict_option_price\u001b[1;34m(tickers, horizon, n_trees)\u001b[0m\n\u001b[0;32m     20\u001b[0m         ticker_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Close\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m         stock_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([stock_data, ticker_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m returns_df \u001b[38;5;241m=\u001b[39m \u001b[43mstock_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(returns_df\u001b[38;5;241m.\u001b[39mcorr())\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:6537\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   6433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6434\u001b[0m \u001b[38;5;124;03mRemove missing values.\u001b[39;00m\n\u001b[0;32m   6435\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6534\u001b[0m \u001b[38;5;124;03m1  Batman  Batmobile 1940-04-25\u001b[39;00m\n\u001b[0;32m   6535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (how \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_default) \u001b[38;5;129;01mand\u001b[39;00m (thresh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_default):\n\u001b[1;32m-> 6537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot set both the how and thresh arguments at the same time.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6539\u001b[0m     )\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01mis\u001b[39;00m no_default:\n\u001b[0;32m   6542\u001b[0m     how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: You cannot set both the how and thresh arguments at the same time."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def predict_option_price(tickers, horizon, n_trees=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    # Fetch historical data for the tickers and calculate daily returns\n",
    "    stock_data = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        if ticker_data.empty:\n",
    "            print(f\"No data available for {ticker}\")\n",
    "            return None\n",
    "        else:\n",
    "            ticker_data = ticker_data[['Close']]\n",
    "            ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
    "            stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "\n",
    "    returns_df = stock_data.pct_change().dropna(how='any', thresh=1)\n",
    "    print(\"Correlation matrix:\")\n",
    "    print(returns_df.corr())\n",
    "    print(f\"Number of NaNs in returns_df: {returns_df.isna().sum().sum()}\")\n",
    "\n",
    "    # Make sure that ticker data exists\n",
    "    if len(returns_df.columns) == 0:\n",
    "        print(f\"No data available for any of the tickers: {tickers}\")\n",
    "        return None\n",
    "\n",
    "    # Define the predictors and the target variables\n",
    "    predictors = returns_df.iloc[-horizon:, :-len(tickers)]\n",
    "    target = returns_df.iloc[-horizon:, len(returns_df.columns)-len(tickers):]\n",
    "\n",
    "    # Fit a Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees)\n",
    "    rf.fit(predictors, target)\n",
    "    \n",
    "    # print predictors and target shapes for debugging\n",
    "    print(f\"predictors shape: {predictors.shape}\")\n",
    "    print(f\"Number of NaNs in predictors: {predictors.isna().sum().sum()}\")\n",
    "    print(f\"target shape: {target.shape}\")\n",
    "    print(f\"Number of NaNs in target: {target.isna().sum().sum()}\")\n",
    "\n",
    "    # Predict returns over the given horizon\n",
    "    predicted_returns = rf.predict(predictors)\n",
    "\n",
    "    # Calculate option prices based on predicted returns\n",
    "    option_values = []\n",
    "    for i in range(len(tickers)):\n",
    "        predicted_return_series = predicted_returns[:,i]\n",
    "        stock_price = stock_data[f\"{tickers[i]}_Close\"][-1]\n",
    "        call_value = max(stock_price * (1 + predicted_return_series) - stock_price, 0)\n",
    "        put_value = max(stock_price - stock_price * (1 + predicted_return_series), 0)\n",
    "        option_values.append((call_value, put_value))\n",
    "\n",
    "    return option_values\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'META']\n",
    "horizon = 2\n",
    "option_values = predict_option_price(tickers, horizon)\n",
    "print(option_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9064268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def predict_option_price(tickers, horizon, n_trees=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "\n",
    "    # Fetch historical data for the tickers and calculate daily returns\n",
    "    stock_data = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        if ticker_data.empty:\n",
    "            print(f\"No data available for {ticker}\")\n",
    "            return None\n",
    "        else:\n",
    "            ticker_data = ticker_data[['Close']]\n",
    "            ticker_data.rename(columns={'Close': f'{ticker}_Close'}, inplace=True)\n",
    "            stock_data = pd.concat([stock_data, ticker_data], axis=1)\n",
    "\n",
    "    returns_df = stock_data.pct_change().dropna(how='all')\n",
    "    print(\"Correlation matrix:\")\n",
    "    print(returns_df.corr())\n",
    "    print(f\"Number of NaNs in returns_df: {returns_df.isna().sum().sum()}\")\n",
    "\n",
    "    # Make sure that ticker data exists\n",
    "    if len(returns_df.columns) == 0:\n",
    "        print(f\"No data available for any of the tickers: {tickers}\")\n",
    "        return None\n",
    "\n",
    "    # Define the predictors and the target variables\n",
    "    predictors = returns_df.iloc[-horizon:, :-len(tickers)]\n",
    "    target = returns_df.iloc[-horizon:, len(returns_df.columns)-len(tickers):]\n",
    "\n",
    "    # Fit a Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees)\n",
    "    rf.fit(predictors, target)\n",
    "\n",
    "    # Predict returns over the given horizon\n",
    "    predicted_returns = rf.predict(predictors)\n",
    "\n",
    "    # Calculate option prices based on predicted returns\n",
    "    option_values = []\n",
    "    for i in range(len(tickers)):\n",
    "        predicted_return_series = predicted_returns[:,i]\n",
    "        stock_price = stock_data[f\"{tickers[i]}_Close\"][-1]\n",
    "        call_value = max(stock_price * (1 + predicted_return_series) - stock_price, 0)\n",
    "        put_value = max(stock_price - stock_price * (1 + predicted_return_series), 0)\n",
    "        option_values.append((call_value, put_value))\n",
    "\n",
    "    return option_values\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'GOOG', 'NFLX', 'META']\n",
    "horizon = 5\n",
    "option_values = predict_option_price(tickers, horizon)\n",
    "print(option_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
