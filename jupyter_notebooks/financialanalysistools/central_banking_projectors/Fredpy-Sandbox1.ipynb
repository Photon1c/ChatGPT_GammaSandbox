{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257dd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one way to import env vars\n",
    "import os\n",
    "import fredpy as fp\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "def set_vars(secrets_file=\"a.env\"):\n",
    "    with open(f\"{secrets_file}\", 'r') as file:\n",
    "        contents = file.read()\n",
    "        env_vars = contents.replace('export ', '').split(\"\\n\")\n",
    "        fp.api_key = env_vars[0].split(\"=\")[1]\n",
    "        print(api_key)\n",
    "set_vars()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9be04b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0f753289e32c3de7c63339d692c2a9fb\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path='../a.env')\n",
    "\n",
    "FED_API_KEY = os.environ['FED_API_KEY']\n",
    "\n",
    "print(FED_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50eab7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bad Request.  The value for variable api_key is not registered.  Read https://fred.stlouisfed.org/docs/api/api_key.html for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\fredapi\\fred.py:64\u001b[0m, in \u001b[0;36mFred.__fetch_data\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     root \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mfromstring(response\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    562\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series_id \u001b[38;5;129;01min\u001b[39;00m series_ids:\n\u001b[1;32m---> 20\u001b[0m     data[series_id] \u001b[38;5;241m=\u001b[39m \u001b[43mfred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(data)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create the figure and axis for the chart\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\fredapi\\fred.py:131\u001b[0m, in \u001b[0;36mFred.get_series\u001b[1;34m(self, series_id, observation_start, observation_end, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    130\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m urlencode(kwargs)\n\u001b[1;32m--> 131\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo data exists for series id: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m series_id)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\fredapi\\fred.py:68\u001b[0m, in \u001b[0;36mFred.__fetch_data\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     67\u001b[0m     root \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mfromstring(exc\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(root\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root\n",
      "\u001b[1;31mValueError\u001b[0m: Bad Request.  The value for variable api_key is not registered.  Read https://fred.stlouisfed.org/docs/api/api_key.html for more information."
     ]
    }
   ],
   "source": [
    "import fredapi\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path='../a.env')\n",
    "\n",
    "FED_API_KEY = os.environ['FED_API_KEY']\n",
    "\n",
    "# Initialize the API client\n",
    "fred = fredapi.Fred(api_key=FED_API_KEY)\n",
    "\n",
    "# Define the series IDs we want to fetch\n",
    "series_ids = ['gdp1']\n",
    "\n",
    "# Fetch the data and create the dataframe\n",
    "data = {}\n",
    "for series_id in series_ids:\n",
    "    data[series_id] = fred.get_series(series_id)\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Create the figure and axis for the chart\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(ax=ax)\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('US Economic Indicators')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "# Show the legend at the bottom\n",
    "ax.legend(loc='lower center', ncol=len(df.columns))\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fredapi\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from fredapi import Fred\n",
    "import fredpy as fp\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "\n",
    "# Set up the FRED API client\n",
    "fred = Fred(api_key=fp.api_key)\n",
    "\n",
    "# Set up the date ranges\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "# Get the data from FRED\n",
    "data = fred.get_series('BOPBCA027NBEA', start_date, end_date)\n",
    "\n",
    "# Convert the data to a dataframe\n",
    "df = pd.DataFrame(data, columns=['Balance of Payments'])\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade5593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a102acd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "series.__init__() got an unexpected keyword argument 'start_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Retrieve the data for the desired series ID\u001b[39;00m\n\u001b[0;32m     14\u001b[0m series_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNRATE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 15\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert the data to a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39m[series_id])\n",
      "\u001b[1;31mTypeError\u001b[0m: series.__init__() got an unexpected keyword argument 'start_date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fredpy as fp\n",
    "from fredapi import Fred\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "\n",
    "# Define the start and end date for the data you want to retrieve\n",
    "start_date = '2022-12-01'\n",
    "end_date = '2023-05-05'\n",
    "\n",
    "# Retrieve the data for the desired series ID\n",
    "series_id = 'UNRATE'\n",
    "data = fp.series(series_id, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[series_id])\n",
    "\n",
    "# Plot the data using Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df.index, df[series_id], label=series_id)\n",
    "ax.set_title(f'{series_id} from {start_date} to {end_date}')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d277518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working chart generator\n",
    "import matplotlib.pyplot as plt\n",
    "from fredapi import Fred\n",
    "import fredpy as fp\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "\n",
    "# Initialize the FRED API client\n",
    "fred = Fred(api_key=fp.api_key)\n",
    "\n",
    "# Define the FRED series ID you want to plot\n",
    "series_id = 'FEDFUNDS'\n",
    "\n",
    "# Retrieve the FRED series data\n",
    "data = fred.get_series(series_id)\n",
    "\n",
    "# Define the start and end date of the chart\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-03-31'\n",
    "\n",
    "# Subset the data based on the start and end date\n",
    "data = data.loc[start_date:end_date]\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(data.index, data.values)\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title(f'{series_id} from {start_date} to {end_date}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69739514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "import fredpy as fp\n",
    "import numpy as np\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "# Replace \"YOUR_API_KEY\" with your actual FRED API key\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "# Search for series containing \"GDP\"\n",
    "results = fred.search(\"BOP\")\n",
    "\n",
    "# Print series IDs from search results\n",
    "for result in results:\n",
    "    #\n",
    "    #print(result.rfind('notes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fredpy as fp\n",
    "from fredapi import Fred\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "def plot_series_fill_between(series_ids):\n",
    "    # Define start and end dates\n",
    "    end_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "    start_date = (pd.Timestamp.today() - pd.DateOffset(years=20)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create empty dataframe to hold data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through series IDs and add data to dataframe\n",
    "    for series_id in series_ids:\n",
    "        fred = Fred(api_key=api_key)\n",
    "        data = fred.get_series(series_id, start_date=start_date, end_date=end_date)\n",
    "        df[series_id] = data\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.set_facecolor('lightgray')\n",
    "    ax.set_title('US Current and Capital Accounts Last 20 Years')\n",
    "\n",
    "    for series_id in series_ids:\n",
    "        ax.fill_between(df.index, df[series_id].min(), df[series_id], alpha=0.5)\n",
    "        ax.plot(df.index, df[series_id], label=series_id)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "series_ids = ['NETFI', 'IEABC']\n",
    "plot_series_fill_between(series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d70dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Series by latest release query\n",
    "from fredapi import Fred\n",
    "import fredpy as fp\n",
    "\n",
    "\n",
    "\n",
    "api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "\n",
    "# Set up the FRED API client\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "\n",
    "# Get list of all series IDs\n",
    "series_ids = fred.get_series_latest_release(\"GDP\")\n",
    "\n",
    "# Print first 10 series IDs\n",
    "print(series_ids[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "import fredpy as fp\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "def get_latest_series():\n",
    "    # Retrieve the 100 most recently updated series\n",
    "    latest_series = Fred.get_series(sort_order='desc', order_by='observation_end', limit=100)\n",
    "\n",
    "    # Get the 25 most recent series by observation end date\n",
    "    latest_series = latest_series.sort_values(by='observation_end', ascending=False).head(25)\n",
    "\n",
    "    # Return the list of series IDs\n",
    "    return latest_series.index.tolist()\n",
    "\n",
    "get_latest_series()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc552515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if Series IDs work\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "base_url = \"https://fred.stlouisfed.org/series/\"\n",
    "series_ids = [\"GDPC1\", \"UNRATE\", \"CPIAUCSL\", \"PAYEMS\", \"BOPBCA027NBEA\"]\n",
    "\n",
    "available_series = []\n",
    "\n",
    "for series_id in series_ids:\n",
    "    url = base_url + series_id\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        available_series.append(series_id)\n",
    "\n",
    "df = pd.DataFrame({\"Series ID\": available_series})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fredpy as fp\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "def plot_series_fill_between(series_ids):\n",
    "    # Define start and end dates\n",
    "    end_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "    start_date = (pd.Timestamp.today() - pd.DateOffset(years=20)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create empty dataframe to hold data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through series IDs and add data to dataframe\n",
    "    for series_id in series_ids:\n",
    "        try:\n",
    "            data = fp.series(series_id)\n",
    "            df[series_id] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for series ID {series_id}: {str(e)}\")\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.set_facecolor('lightgray')\n",
    "    ax.set_title('US Current and Capital Accounts Last 20 Years')\n",
    "\n",
    "    for series_id in series_ids:\n",
    "        if np.isna(df[series_id]).all():\n",
    "            ax.fill_between(df.index, 0, df[series_id], alpha=0.5)\n",
    "            ax.plot(df.index, df[series_id], label=series_id)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "series_ids = ['NETFI', 'IEABC', 'INVALID']\n",
    "plot_series_fill_between(series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://fred.stlouisfed.org/series/'\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Find all the series IDs in the page\n",
    "series_ids = []\n",
    "for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href is not None and href.startswith(url):\n",
    "        series_id = href[len(url):]\n",
    "        series_ids.append(series_id)\n",
    "\n",
    "# Filter the active series IDs\n",
    "active_series_ids = []\n",
    "for series_id in series_ids:\n",
    "    series_url = f\"{url}{series_id}\"\n",
    "    response = requests.get(series_url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    status_tag = soup.find_all('a', class_='series-title')\n",
    "    active_series_ids.append(series_id)\n",
    "\n",
    "# Print the active series IDs\n",
    "print(active_series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d819e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://fred.stlouisfed.org/tags/series'\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "series_links = soup.find_all('a', class_='series-title')\n",
    "series_ids = [link['href'].split('/')[-1] for link in series_links]\n",
    "\n",
    "print(series_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write series IDs to CSV file\n",
    "import string\n",
    "import itertools\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def get_ids():\n",
    "    # generate a list of potential series IDs\n",
    "    letters = string.ascii_uppercase\n",
    "    numbers = '0123456789'\n",
    "    patterns = ['{}{}{}', '{}{}{}{}', '{}{}{}{}{}', '{}_{}{}{}', '{}_{}{}{}{}', '{}_{}{}{}{}{}']\n",
    "    combinations = itertools.product(letters + numbers, repeat=6)\n",
    "    potential_series_ids = (pattern.format(*combo) for combo in combinations for pattern in patterns)\n",
    "\n",
    "    # test each series ID and write the list of working series IDs to a CSV file\n",
    "    base_url = 'https://fred.stlouisfed.org/series/{}'\n",
    "    working_series_ids = []\n",
    "    with open('working_series_ids.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Series ID'])\n",
    "        for series_id in potential_series_ids:\n",
    "            url = base_url.format(series_id)\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                working_series_ids.append(series_id)\n",
    "                writer.writerow([series_id])\n",
    "    return working_series_ids\n",
    "working_series_ids = get_ids()\n",
    "print(working_series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c395e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SP500', 'GDP', 'UNRATE', 'DGS10', 'CPALTT01USM657N', 'CPIAUCSL', 'PAYEMS', 'M2SL']\n"
     ]
    }
   ],
   "source": [
    "#Test Series IDs by returning 200 code\n",
    "import requests\n",
    "\n",
    "# generate a list of series IDs to test\n",
    "series_ids = ['SP500', 'GDP', 'UNRATE', 'DGS10', 'CPALTT01USM657N', 'CPIAUCSL', 'PAYEMS', 'M2SL']\n",
    "\n",
    "working_series_ids = []\n",
    "\n",
    "# test each series ID\n",
    "for series_id in series_ids:\n",
    "    url = f\"https://fred.stlouisfed.org/series/{series_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        working_series_ids.append(series_id)\n",
    "\n",
    "# print the list of working series IDs\n",
    "print(working_series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append available series IDs to CSV file\n",
    "#warning: too powerful!\n",
    "import csv\n",
    "import string\n",
    "import itertools\n",
    "import requests\n",
    "\n",
    "# generate a list of potential series IDs\n",
    "letters = string.ascii_uppercase\n",
    "numbers = '0123456789'\n",
    "patterns = ['{}{}{}', '{}{}{}{}', '{}{}{}{}{}', '{}_{}{}{}', '{}_{}{}{}{}', '{}_{}{}{}{}{}']\n",
    "combinations = itertools.product(letters + numbers, repeat=6)\n",
    "potential_series_ids = (pattern.format(*combo) for combo in combinations for pattern in patterns)\n",
    "\n",
    "# test each series ID and append the list of working series IDs to a CSV file\n",
    "base_url = 'https://fred.stlouisfed.org/series/{}'\n",
    "working_series_ids = []\n",
    "for series_id in potential_series_ids:\n",
    "    url = base_url.format(series_id)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        working_series_ids.append(series_id)\n",
    "        with open('fred_series.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([series_id])\n",
    "\n",
    "print(working_series_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83397b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news menu found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_fed_news():\n",
    "    url = 'https://www.federalreserve.gov'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    news_menu = soup.select_one('#newsMenu a[href=\"/newsevents.htm\"]')\n",
    "    if news_menu:\n",
    "        news_url = url + news_menu['href']\n",
    "        news_response = requests.get(news_url)\n",
    "        news_soup = BeautifulSoup(news_response.content, 'html.parser')\n",
    "        article_links = news_soup.select('.news-item .col-xs-12 h3 a')\n",
    "        for link in article_links:\n",
    "            print(link.text.strip())\n",
    "            print(link['href'])\n",
    "    else:\n",
    "        print('No news menu found.')\n",
    "\n",
    "get_fed_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9689a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news menu found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.federalreserve.gov/newsevents.htm'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "news_menu = soup.select_one('#article div.col-xs-12.col-sm-8.col-md-9.col-lg-9 h3')\n",
    "if news_menu:\n",
    "    print(news_menu.text.strip())\n",
    "else:\n",
    "    print('No news menu found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f2c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
