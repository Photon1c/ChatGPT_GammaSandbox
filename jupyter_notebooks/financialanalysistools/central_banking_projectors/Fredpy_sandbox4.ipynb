{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cirq\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import fredpy as fp\n",
    "#from fredapi import Fred\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "#fp = Fred(api_key=fp.api_key)\n",
    "\n",
    "api_key = fp.api_key\n",
    "\n",
    "# FRED series ID to retrieve data for\n",
    "series_id = 'SP500'\n",
    "\n",
    "# Number of steps in the prediction\n",
    "num_steps = 30\n",
    "\n",
    "# Request data from FRED API\n",
    "url = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json'\n",
    "response = requests.get(url)\n",
    "data = json.loads(response.text)['observations']\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean data and prepare for prediction\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "start_date = df.index[-1]\n",
    "end_date = start_date + pd.DateOffset(days=num_steps)\n",
    "dates = pd.date_range(start_date, end_date)\n",
    "\n",
    "# Prepare quantum circuit and simulator\n",
    "# Update qubit initialization to match circuit definition\n",
    "qubit = cirq.GridQubit(0, 0)\n",
    "\n",
    "# Update circuit definition to measure qubit in the X basis\n",
    "circuit = cirq.Circuit(cirq.X(qubit), cirq.measure(qubit, key='0'))\n",
    "\n",
    "\n",
    "def generate_predictions(steps):\n",
    "    predictions = []\n",
    "    for i in range(steps):\n",
    "        result = simulator.run(circuit, repetitions=100)\n",
    "        counts = result.histogram(key='0,')[0]\n",
    "        if 1 in counts:\n",
    "            predictions.append(counts[1] / sum(counts))\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    if not predictions:\n",
    "        raise ValueError(\"No predictions generated.\")\n",
    "    # Fit predictions to a log-linear power law function\n",
    "    x = np.arange(1, steps+1)\n",
    "    y = np.log(predictions)\n",
    "    popt, pcov = curve_fit(lambda t,a,b: a*np.log(t)+b,  x,  y)\n",
    "    a, b = popt\n",
    "    predictions_fit = np.exp(a*np.log(x) + b)\n",
    "    return predictions_fit\n",
    "\n",
    "\n",
    "# Define function to generate predictions\n",
    "num_steps = 20\n",
    "predictions = generate_predictions(num_steps)\n",
    "\n",
    "plt.plot(predictions, label='Predictions')\n",
    "plt.plot(predictions_fit, label='Fitted curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "def plot_stock_price_projection():\n",
    "    # Read CSV file and extract date and value columns\n",
    "    df = pd.read_csv(\"input.csv\", usecols=[0,1], parse_dates=[0])\n",
    "    df = df.dropna()  # Remove rows with empty values\n",
    "    dates = df['date']\n",
    "    values = df['value']\n",
    "\n",
    "    # Define log linear power law function for projection\n",
    "    def log_linear_power_law(x, a, b, c):\n",
    "        return a * x**b + c\n",
    "\n",
    "    # Fit function to historical data\n",
    "    popt, pcov = scipy.optimize.curve_fit(log_linear_power_law, range(len(values)), values)\n",
    "\n",
    "    # Generate projection values for 2 years\n",
    "    projection_range = range(len(values), len(values) + 365*2)\n",
    "    projection_values = [log_linear_power_law(x, *popt) for x in projection_range]\n",
    "\n",
    "    # Plot historical data and projection\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates, values, label='Historical')\n",
    "    ax.plot(pd.date_range(start=dates.iloc[-1], periods=len(projection_values), freq='D'), projection_values, label='Projection')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.set_title('Stock Price Projection')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "plot_stock_price_projection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirq.contrib.svg import SVGCircuit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cirq\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import fredpy as fp\n",
    "\n",
    "\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "fp = Fred(api_key=fp.api_key)\n",
    "\n",
    "api_key = fp.api_key\n",
    "\n",
    "# FRED series ID to retrieve data for\n",
    "series_id = 'SP500'\n",
    "\n",
    "# Define the start and end date of the chart\n",
    "start_date = '2020-01-01'\n",
    "#end_date = '2023-03-31' This script does not need this line but could be worked into code\n",
    "\n",
    "\n",
    "# Set up the circuit\n",
    "qubits = [cirq.GridQubit(0, i) for i in range(3)]\n",
    "circuit = cirq.Circuit()\n",
    "circuit.append(cirq.H(q) for q in qubits)\n",
    "circuit.append(cirq.measure(*qubits, key='m'))\n",
    "\n",
    "# Set up the simulator\n",
    "simulator = cirq.Simulator()\n",
    "\n",
    "# Simulate the circuit\n",
    "num_shots = 1000\n",
    "result = simulator.run(circuit, repetitions=num_shots)\n",
    "\n",
    "# Get the probabilities of the final state\n",
    "num_qubits = len(qubits)\n",
    "probs = []\n",
    "for i in range(num_qubits):\n",
    "    if i in result.multi_measurement_histogram_dict():\n",
    "        probs.append(result.multi_measurement_histogram_dict()[i][0]/num_shots)\n",
    "    else:\n",
    "        probs.append(0)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = []\n",
    "if '0' in result.measurements:\n",
    "    predictions.append(result.measurements['0'][0])\n",
    "else:\n",
    "    predictions.append(0)\n",
    "\n",
    "# Create the dates list\n",
    "dates = pd.date_range(start=start_date, periods=30, freq='D')\n",
    "\n",
    "# Create the predictions DataFrame\n",
    "if len(predictions) < len(dates):\n",
    "    dates = dates[:len(predictions)]\n",
    "elif len(predictions) > len(dates):\n",
    "    new_date = pd.date_range(start=dates[-1], periods=2, freq='D')[1]\n",
    "    dates = dates.append(new_date)\n",
    "df_pred = pd.DataFrame(predictions, index=dates, columns=['predictions'])\n",
    "\n",
    "# Print the predictions DataFrame\n",
    "print(df_pred)\n",
    "\n",
    "# Create the circuit diagram\n",
    "circuit_diagram = SVGCircuit(circuit)\n",
    "print(circuit_diagram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2edc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from fredapi import Fred\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import fredpy as fp\n",
    "\n",
    "\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "fp = Fred(api_key=fp.api_key)\n",
    "\n",
    "api_key = fp.api_key\n",
    "\n",
    "# FRED series ID to retrieve data for\n",
    "series_id = 'SP500'\n",
    "\n",
    "def simulate_circuit(series_id, num_shots):\n",
    "    # Download data from FRED\n",
    "    fred = Fred(api_key=api_key)\n",
    "    data = fred.get_series(series_id)\n",
    "    dates = [d.strftime('%Y-%m-%d') for d in data.index]\n",
    "\n",
    "    # Initialize circuit\n",
    "    num_qubits = len(dates)\n",
    "    circuit = cirq.Circuit()\n",
    "\n",
    "    # Add Hadamard gates to create a uniform superposition\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.H(qubit))\n",
    "\n",
    "    # Add phase flip gates based on the data\n",
    "    for i, datum in enumerate(data):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        if datum > data.mean():\n",
    "            circuit.append(cirq.Z(qubit))\n",
    "\n",
    "    # Add measurement gates to the circuit\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.measure(qubit, key='m{}'.format(i)))\n",
    "\n",
    "    # Simulate the circuit\n",
    "    simulator = cirq.Simulator()\n",
    "    result = simulator.run(circuit, repetitions=num_shots)\n",
    "\n",
    "    # Calculate probabilities for each date\n",
    "    probs = []\n",
    "    for i in range(num_qubits):\n",
    "        if 'm{}'.format(i) in result.histograms:\n",
    "            probs.append(result.histogram(key='m')[i] / num_shots)\n",
    "        else:\n",
    "            probs.append(0)\n",
    "\n",
    "    # Create Pandas DataFrame with results\n",
    "    df_pred = pd.DataFrame(probs, index=dates, columns=['probabilities'])\n",
    "    return df_pred\n",
    "df = simulate_circuit('SP500', 1000)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba10167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from fredapi import Fred\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import fredpy as fp\n",
    "\n",
    "\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "fp = Fred(api_key=fp.api_key)\n",
    "\n",
    "api_key = fp.api_key\n",
    "\n",
    "\n",
    "\n",
    "def simulate_circuit(series_id, num_shots):\n",
    "    # Download data from FRED\n",
    "    fred = Fred(api_key=api_key)\n",
    "    data = fred.get_series(series_id)\n",
    "    dates = [d.strftime('%Y-%m-%d') for d in data.index]\n",
    "\n",
    "    # Initialize circuit\n",
    "    num_qubits = len(dates)\n",
    "    circuit = cirq.Circuit()\n",
    "\n",
    "    # Add Hadamard gates to create a uniform superposition\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.H(qubit))\n",
    "\n",
    "    # Add phase flip gates based on the data\n",
    "    for i, datum in enumerate(data):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        if datum > data.mean():\n",
    "            circuit.append(cirq.Z(qubit))\n",
    "\n",
    "    # Add measurement gates to the circuit\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.measure(qubit, key='m{}'.format(i)))\n",
    "\n",
    "    # Simulate the circuit\n",
    "    simulator = cirq.Simulator()\n",
    "    result = simulator.run(circuit, repetitions=num_shots)\n",
    "\n",
    "    # Calculate probabilities for each date\n",
    "    probs = []\n",
    "    for i in range(num_qubits):\n",
    "        if 'm{}'.format(i) in result.measurements.keys():\n",
    "            measurements = result.measurements['m{}'.format(i)]\n",
    "            hist = measurements.histogram(key='result')\n",
    "            counts = hist.to_dict()\n",
    "            probs.append(counts[0] / num_shots)\n",
    "        else:\n",
    "            probs.append(0)\n",
    "        \n",
    "    # Create Pandas DataFrame with results\n",
    "    df_pred = pd.DataFrame(probs, index=dates, columns=['probabilities'])\n",
    "    return df_pred\n",
    "df = simulate_circuit('SP500', 1000)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_fred_data(series_id, api_key):\n",
    "    \"\"\"\n",
    "    This function retrieves data for a given series ID from the FRED API and returns it as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    base_url = 'https://api.stlouisfed.org/fred/series/observations?series_id={}&api_key={}'.format(series_id, api_key)\n",
    "    response = requests.get(base_url)\n",
    "    data = json.loads(response.text)['observations']\n",
    "    dates = []\n",
    "    values = []\n",
    "    for observation in data:\n",
    "        dates.append(datetime.strptime(observation['date'], '%Y-%m-%d').date())\n",
    "        values.append(float(observation['value']))\n",
    "    df = pd.DataFrame({'value': values}, index=dates)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_predictions(qubit, length):\n",
    "    \"\"\"\n",
    "    This function generates a Cirq circuit to predict a binary time series based on a given input qubit, and returns\n",
    "    the predictions as a list of percentages.\n",
    "    \"\"\"\n",
    "    circuit = cirq.Circuit(\n",
    "        cirq.H(qubit),\n",
    "        cirq.measure(qubit, key='0')\n",
    "    )\n",
    "    predictions = []\n",
    "    for i in range(length):\n",
    "        simulator = cirq.Simulator()\n",
    "        result = simulator.run(circuit, repetitions=100)\n",
    "        count = result.histogram(key='0')\n",
    "        predictions.append(count[1] / sum(count))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def simulate_and_predict(df, qubit):\n",
    "    \"\"\"\n",
    "    This function generates a series of binary predictions for a given input DataFrame and qubit.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            # Initialize with a uniform superposition\n",
    "            circuit = cirq.Circuit(cirq.X(qubit), cirq.H(qubit))\n",
    "        else:\n",
    "            # Condition on the previous value\n",
    "            if df.iloc[i-1]['value'] == 1:\n",
    "                circuit = cirq.Circuit(cirq.X(qubit), cirq.H(qubit))\n",
    "            else:\n",
    "                circuit = cirq.Circuit(cirq.H(qubit))\n",
    "        result = cirq.Simulator().run(circuit, repetitions=100)\n",
    "        count = result.histogram(key='0')\n",
    "        prediction = count[1] / sum(count)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def analyze_results(results, qubits):\n",
    "    \"\"\"\n",
    "    This function analyzes the results of a set of circuit simulations and returns a histogram of the number of times each\n",
    "    qubit was measured in the |1> state.\n",
    "    \"\"\"\n",
    "    histograms = []\n",
    "    for i, qubit in enumerate(qubits):\n",
    "        m_results = []\n",
    "        for result in results:\n",
    "            counts = result.measurements[str(qubit)]\n",
    "            m_result = np.count_nonzero(counts)\n",
    "            m_results.append(m_result)\n",
    "        histograms.append(np.histogram(m_results, bins=range(len(results) + 1))[0])\n",
    "    return histograms\n",
    "\n",
    "\n",
    "def plot_predictions(df, predictions):\n",
    "    \"\"\"\n",
    "    This function plots the predictions along with the original time series data.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.fill_between(df.index, 0, 1, where=df['value'] == 1, color='b', alpha=0.1, interpolate=True)\n",
    "    ax.fill_between(df.index, 0, 1, where=df['value'] == 0, color='r', alpha=0.1, interpolate=True)\n",
    "    ax.plot(df.index, predictions, label='predictions')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define the FRED series ID and number of qubits\n",
    "    series_id = \"GDPC1\"\n",
    "    num_qubits = 8\n",
    "\n",
    "    # Convert FRED data to qubits\n",
    "    circuit = fred_data_to_qubits(series_id, num_qubits)\n",
    "\n",
    "    # Simulate the circuit\n",
    "    num_simulations = 1000\n",
    "    percentages = simulate_circuit(circuit, num_simulations)\n",
    "\n",
    "    # Create a Pandas DataFrame with the simulation results\n",
    "    start_date = datetime.now() - timedelta(days=num_simulations)\n",
    "    dates = pd.date_range(start_date, periods=num_simulations, freq=\"D\")\n",
    "    df_pred = pd.DataFrame(percentages, index=dates, columns=[\"Percentage\"])\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df_pred.index, df_pred[\"Percentage\"])\n",
    "    ax.fill_between(df_pred.index, 0, df_pred[\"Percentage\"], alpha=0.1)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Percentage\")\n",
    "    ax.set_title(\"Prediction of FRED Data\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9cda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(16, input_shape=input_shape, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def predict_time_series(data, future_dates):\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "\n",
    "    # Normalize the data\n",
    "    train_mean = train_data.mean()\n",
    "    train_std = train_data.std()\n",
    "    train_data = (train_data - train_mean) / train_std\n",
    "    test_data = (test_data - train_mean) / train_std\n",
    "\n",
    "    # Create input and output sequences for the model\n",
    "    def create_sequences(data, window_size):\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for i in range(window_size, len(data)):\n",
    "            xs.append(data[i-window_size:i])\n",
    "            ys.append(data[i])\n",
    "        return tf.convert_to_tensor(xs), tf.convert_to_tensor(ys)\n",
    "\n",
    "    window_size = 10\n",
    "    train_xs, train_ys = create_sequences(train_data, window_size)\n",
    "    test_xs, test_ys = create_sequences(test_data, window_size)\n",
    "\n",
    "    # Train the model\n",
    "    model = create_model((window_size,))\n",
    "    history = model.fit(train_xs, train_ys, epochs=50, verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    future_data = data[-window_size:]\n",
    "    future_data = (future_data - train_mean) / train_std\n",
    "    for date in future_dates:\n",
    "        prediction = model.predict(tf.convert_to_tensor(future_data.reshape((1, window_size))))\n",
    "        data = data.append(pd.Series(prediction[0]), ignore_index=True)\n",
    "        future_data = data[-window_size:]\n",
    "        future_data = (future_data - train_mean) / train_std\n",
    "\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('input.csv')\n",
    "\n",
    "future_dates = ['2023-09-09', '2023-12-10', '2024-04-11']\n",
    "\n",
    "predicted_data = predict_time_series(data, future_dates)\n",
    "print(predicted_data.tail(len(future_dates)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(16, input_shape=input_shape, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data)-window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def predict_time_series(data, future_dates):\n",
    "    # Load data\n",
    "    data = pd.read_csv('input.csv')\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "\n",
    "    # Normalize the data\n",
    "    train_mean = train_data.mean()\n",
    "    train_std = train_data.std()\n",
    "    train_data = (train_data - train_mean) / train_std\n",
    "    test_data = (test_data - train_mean) / train_std\n",
    "\n",
    "    # Create input and output sequences for the model\n",
    "    window_size = 10\n",
    "    train_xs, train_ys = create_sequences(train_data, window_size)\n",
    "    test_xs, test_ys = create_sequences(test_data, window_size)\n",
    "\n",
    "    # Train the model\n",
    "    model = create_model((window_size,))\n",
    "    history = model.fit(train_xs, train_ys, epochs=50, verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    future_data = data[-window_size:]\n",
    "    future_data = (future_data - train_mean) / train_std\n",
    "    for date in future_dates:\n",
    "        prediction = model.predict(tf.convert_to_tensor(future_data.reshape((1, window_size))))\n",
    "        data = data.append(pd.Series(prediction[0]), ignore_index=True)\n",
    "        future_data = data[-window_size:]\n",
    "        future_data = (future_data - train_mean) / train_std\n",
    "\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('input.csv')\n",
    "\n",
    "future_dates = ['2023-09-09', '2023-12-10', '2024-04-11']\n",
    "\n",
    "predicted_data = predict_time_series(data, future_dates)\n",
    "print(predicted_data.tail(len(future_dates)))\n",
    "\n",
    "def plot_results(data, future_dates, predicted_data):\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Plot the actual data\n",
    "    ax.plot(data.index, data.values, label='Actual')\n",
    "\n",
    "    # Plot the projected data\n",
    "    future_index = pd.date_range(start=data.index[-1], periods=len(future_dates)+1, freq='M')[1:]\n",
    "    ax.plot(future_index, predicted_data[-len(future_dates):].values, label='Projected')\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    ax.set_title('Projected Data')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "    # Set the x-axis ticks to be every 3 months\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_results(data, future_dates, predicted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d44006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7746ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from fredapi import Fred\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import fredpy as fp\n",
    "\n",
    "\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "fp = Fred(api_key=fp.api_key)\n",
    "\n",
    "api_key = fp.api_key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def simulate_circuit(series_id, num_shots):\n",
    "    # Download data from FRED\n",
    "    fred = Fred(api_key=api_key)\n",
    "    data = fred.get_series(series_id)\n",
    "    dates = [d.strftime('%Y-%m-%d') for d in data.index]\n",
    "\n",
    "    # Initialize circuit\n",
    "    num_qubits = len(dates)\n",
    "    circuit = cirq.Circuit()\n",
    "\n",
    "    # Add Hadamard gates to create a uniform superposition\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.H(qubit))\n",
    "\n",
    "    # Add phase flip gates based on the data\n",
    "    for i, datum in enumerate(data):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        if datum > data.mean():\n",
    "            circuit.append(cirq.Z(qubit))\n",
    "\n",
    "    # Add measurement gates to the circuit\n",
    "    for i in range(num_qubits):\n",
    "        qubit = cirq.GridQubit(0, i)\n",
    "        circuit.append(cirq.measure(qubit, key='m{}'.format(i)))\n",
    "\n",
    "    # Simulate the circuit\n",
    "    simulator = cirq.Simulator()\n",
    "    result = simulator.run(circuit, repetitions=num_shots)\n",
    "\n",
    "    # Calculate probabilities for each date\n",
    "    probs = []\n",
    "    for i in range(num_qubits):\n",
    "        if 'm{}'.format(i) in result.measurements.keys():\n",
    "            measurements = result.measurements['m{}'.format(i)]\n",
    "            hist = measurements.histogram(key='result')\n",
    "            counts = hist.to_dict()\n",
    "            probs.append(counts[0] / num_shots)\n",
    "        else:\n",
    "            probs.append(0)\n",
    "\n",
    "    # Create Pandas DataFrame with results\n",
    "    df_pred = pd.DataFrame(probs, index=dates, columns=['probabilities'])\n",
    "\n",
    "    return df_pred\n",
    "df = simulate_circuit('SP500', 1000)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d7d7aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'observations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.stlouisfed.org/fred/series/observations?series_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&api_key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&file_type=json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m---> 19\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobservations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Clean data and prepare for prediction\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'observations'"
     ]
    }
   ],
   "source": [
    "#Simulate a quantum projection for the federal funds rate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cirq\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import fredpy as fp\n",
    "\n",
    "fp.api_key = fp.load_api_key('cucumber.txt')\n",
    "\n",
    "api_key = fp.api_key\n",
    "series_id = 'mhb'\n",
    "num_steps = 500\n",
    "\n",
    "# Request data from FRED API\n",
    "url = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json'\n",
    "response = requests.get(url)\n",
    "data = json.loads(response.text)['observations']\n",
    "\n",
    "\n",
    "# Clean data and prepare for prediction\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "start_date = df.index[-1]\n",
    "end_date = start_date + pd.DateOffset(days=num_steps-1)  # Subtract 1 from num_steps\n",
    "dates = pd.date_range(start_date, end_date)\n",
    "\n",
    "#Define Qubits\n",
    "num_qubits = len(dates)\n",
    "qubit = cirq.GridQubit(0, 0)\n",
    "\n",
    "# Add measurement gate to circuit\n",
    "circuit = cirq.Circuit()\n",
    "circuit.append(cirq.measure(qubit))\n",
    "simulator = cirq.Simulator()\n",
    "# Run simulation\n",
    "result = simulator.run(circuit, repetitions=100)\n",
    "\n",
    "# Define quantum circuit and simulator\n",
    "\n",
    "circuit = cirq.Circuit(cirq.X(qubit), cirq.measure(qubit)) # Add measurement\n",
    "\n",
    "\n",
    "# Define function to generate predictions\n",
    "def generate_predictions(steps):\n",
    "    predictions = []\n",
    "    for i in range(steps):\n",
    "        simulator = cirq.Simulator()\n",
    "        result = simulator.run(circuit, repetitions=100)\n",
    "        count = result.histogram(key=str(q))\n",
    "        predictions.append(count[1] / sum(count))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "predictions = generate_predictions(num_steps)\n",
    "\n",
    "# Calculate probability ranges\n",
    "df_pred = pd.DataFrame(predictions, index=dates, columns=['predictions'])\n",
    "df_prob = df_pred.groupby(pd.Grouper(freq='W')).agg(['mean', 'std'])\n",
    "df_prob['ci_lower'] = df_prob[('predictions', 'mean')] - df_prob[('predictions', 'std')]\n",
    "df_prob['ci_upper'] = df_prob[('predictions', 'mean')] + df_prob[('predictions', 'std')]\n",
    "\n",
    "# Plot predictions with fill_between style\n",
    "plt.fill_between(df_prob.index, df_prob['ci_lower'], df_prob['ci_upper'], alpha=0.2)\n",
    "plt.plot(df.index, df['value'], label=series_id)\n",
    "plt.legend()\n",
    "# Add axis labels and title\n",
    "plt.xlabel('Dates of Observation')\n",
    "plt.ylabel(series_id)\n",
    "plt.title(series_id)\n",
    "plt.show()\n",
    "\n",
    "# Print probability ranges as Pandas data frame\n",
    "print(df_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate predictions. Ideally this would be fitten to the historical data points. \n",
    "#Log linear power laws just smooth out the series, we want functions with more predictive power\n",
    "\n",
    "def generate_predictions(steps):\n",
    "    predictions = []\n",
    "    for i in range(length):\n",
    "        simulator = cirq.Simulator()\n",
    "        result = simulator.run(circuit, repetitions=100)\n",
    "        counts = result.histogram(key='0')[0]\n",
    "        predictions.append(counts[1] / sum(counts))\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ee00dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dpicpi.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Load CSV data into a DataFrame\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdpicpi.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Forecast the next 5 years of data\u001b[39;00m\n\u001b[0;32m     42\u001b[0m forecast_time_series(data, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dpicpi.csv'"
     ]
    }
   ],
   "source": [
    "#Create stock forecasting function\n",
    "#Quantify consumption goods, waste, and leisure\n",
    "#Use FRED DPI/CPI \n",
    "#Build forecast ARIMA model\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Define function to forecast time series data using ARIMA model and plot the results\n",
    "def forecast_time_series(data, steps):\n",
    "    # Convert date column to datetime format\n",
    "    data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "\n",
    "    # Set date column as index\n",
    "    data.set_index('DATE', inplace=True)\n",
    "\n",
    "    # Create the ARIMA model\n",
    "    model = ARIMA(data, order=(1,1,1))\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Forecast the next n steps of data\n",
    "    forecast = model_fit.forecast(steps=steps)\n",
    "\n",
    "    # Combine the historical data with the forecast\n",
    "    full_data = pd.concat([data, forecast.to_frame('FORECAST')], axis=0)\n",
    "\n",
    "    # Visualize the historical data and forecast\n",
    "    plt.plot(full_data)\n",
    "    plt.legend(full_data.columns)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('DSPI_CPIAUCSL_NBD')\n",
    "    plt.title('DSPI_CPIAUCSL_NBD Time Series Forecast')\n",
    "    plt.show()\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "data = pd.read_csv('dpicpi.csv')\n",
    "\n",
    "# Forecast the next 5 years of data\n",
    "forecast_time_series(data, steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbaea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
